# -*- coding: utf-8 -*-
"""1_RO_LULC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PzDp3iSNa54qPRJAASo8lJuvBp8-9TDg

# **Rastgele Orman (Random Forest) Yöntemi ile Arazi Örtüsü ve Kullanımı Sınıflandırması**

<img  src="https://raw.githubusercontent.com/geoaihub/geoaihub/main/assets/Mersin%20GeoAI%20Hub%202.png"  height=400  width=1000  alt="https://github.com/geoaihub"/>  

<small>Kaynak: <a  href="https://github.com/geoaihub">GeoAIHub Mersin GitHub</a></small>

<br>

Bu çalışmada, Çukurova Havzası’nın arazi örtüsü ve arazi kullanımı sınıflandırması için Sentinel-2 uydu görüntülerinden alınan dokuz adet bant ve dokuz adet indeks (örneğin NDVI, NDWI, NDTI) kullanılmıştır. Ayrıca, Sayısal Yükseklik Modeli (SYM) de sınıflandırma sürecine dahil edilmiştir. Eğitim verisi, 18 Ağustos 2023 tarihli bir Sentinel-2 görüntüsünden oluşturulmuş ve toplamda orijinal veri setinde 1,575,249 piksel etiketlenmiştir. Bu veri seti, her bir sınıf için yaklaşık 20,000 etiketli nokta kullanılarak 100,000 etiketli nokta ile oluşturulmuştur. Sınıflandırma için yedi farklı makine öğrenmesi ve üç derin öğrenme modeli uygulanmış, modellerin performansı F-1 Skoru, Doğruluk ve Kappa gibi metriklerle değerlendirilmiştir.


Çalışmanın temel amacı, hangi özniteliklerin (bantlar ve indeksler) sınıflandırma sürecinde en etkili olduğunu belirlemektir. Bu bağlamda, SHapley Additive Explanations (SHAP) gibi açıklanabilir yapay zekâ yöntemleri kullanılarak, sınıflandırma modellerinin nasıl karar verdiği ve hangi özelliklerin önemli olduğu açıklanmıştır. Çalışma, bu yöntemlerin, özellikle görüntü sınıflandırması gibi karmaşık problemlerde, modelin anlaşılabilirliğini ve optimizasyonunu nasıl desteklediğini göstermektedir.

## **Hedefler**

1. **Uydu Görüntülerinin Sınıflandırılması**  
   Sentinel-2 uydu görüntülerinden elde edilen verilerle arazi örtüsü ve arazi kullanımı sınıflandırması yapmak.

2. **Veri Ön İşleme**  
   Uydu görüntülerinden özellikler çıkararak (örneğin, indeksler: NDVI, NDWI, NDTI) sınıflandırıcıya beslenebilecek bir özellik matrisi oluşturmak.

3. **Modelin Performansını Değerlendirmek**  
   Modelin doğruluğunu ve performansını değerlendirmek, F-1 Skoru ve Kappa gibi metriklerle sonuçları analiz etmek.

4. **Modelin Açıklanabilirliğini Sağlamak**  
   SHAP (SHapley Additive Explanations) yöntemi ile modelin karar süreçlerini açıklamak ve hangi özelliklerin sınıflandırma kararında etkili olduğunu belirlemek.

5. **Sonuçları Görselleştirmek**  
   Sınıflandırma sonuçlarını harita üzerinde görselleştirmek ve farklı arazi örtüsü türlerini analiz etmek.

## **0. İlk Adımlar**

### **0.1. Google Drive'a Bağlan**
"""

# from google.colab import drive
# drive.mount('/gdrive')

"""### **0.2. Kütüphaneleri İndir**"""

!pip install shap -q

!pip install joblib -q

"""### **0.3. Kütüphaneleri İçe Aktar**"""

import shap

import joblib

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import GridSearchCV

from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.preprocessing import LabelEncoder

from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm

import time
import joblib

"""## **1. Veri Ön İşleme**

### **1.1. Veri Setini Yükleme ve Ön Hazırlık**
"""

df = pd.read_csv('/content/df.csv')

df.head(10)

df.tail(10)

df['Class'].value_counts()

label_encoder = LabelEncoder()
df['Class_Encoded'] = label_encoder.fit_transform(df['Class'])
df.head()

for i in range(len(df['Class'].unique())):
  print(f"Sınıf: {df['Class'].unique()[i]}, İndis: {df['Class_Encoded'].unique()[i]}")

"""### **1.2. Veri Setinin İstatistiksel Analizi**"""

df.info()

df.describe().T

X = df.iloc[:, :19]
y = df.iloc[:, -1]

X.head()

y.head()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Şimdi elimizde `X_train` (bağımsız sütunlar için eğitim verisi), `X_test` (bağımsız sütunlar için test verisi), `y_train` (bağımlı sütun için eğitim verisi) ve `y_test` (bağımlı sütun için test verisi) var."""

print("Length of X_train:", len(X_train))
print("Length of X_test:", len(X_test))
print("Length of y_train:", len(y_train))
print("Length of y_test:", len(y_test))

"""## **2. Rastgele Orman Modeli Eğitimi**

Bu çalışmada, `RandomForestClassifier` sınıflandırıcısı kullanıldı. Eğitim sonucunda, `evaluate_classifier` fonksiyonu ile sınıflandırıcı değerlendirildi ve doğruluk, hassasiyet, geri çağırma ve F1 skoru gibi metrikler hesaplanıp yazdırıldı. Son olarak, en iyi parametreler ve metrikler (doğruluk, hassasiyet, geri çağırma, F1 skoru) matplotlib ve seaborn ile histogramlar halinde görselleştirildi. Bu histogramlar, parametrelerin sınıflandırıcı performansına etkilerini anlamaya yardımcı oldu.
"""

# class_labels = ['Agriculture Area', 'Artificial Land', 'Barren Land', 'Forest', 'Water Area']
class_labels = ['Tarım Alanı', 'Yapay Arazi', 'Çorak Arazi', 'Orman', 'Su Alanı']

"""Artık sınıflandırıcıyı oluşturabiliriz."""

rf = RandomForestClassifier()

RandomForestClassifier().get_params()

"""### **2.1. Hiperparametrelerin Belirlenmesi**

İlk adım, `RandomForestClassifier` için kullanılacak hiperparametreleri belirlemektir. Bu parametreler, modelin nasıl çalışacağını ve hangi performans seviyelerine ulaşacağını etkiler.
"""

rf_params = {'max_depth': 30, 'min_samples_leaf': 1}

"""- `max_depth`: Modelin karar ağaçlarının ne kadar derin olacağını belirler. Burada, ağaçlar 30 derinliğe kadar uzayabilir.
- `min_samples_leaf`: Her bir yaprak düğümünde bulunması gereken minimum örnek sayısını belirler. Burada, en az 1 örnekle yaprak düğümüne ulaşılmasına izin verilmektedir.

### **2.2. Sınıf Oluşturma**

Modeli başlatırken, belirlediğimiz hiperparametreleri kullanarak `RandomForestClassifier` sınıfını oluşturuyoruz.
"""

clf = RandomForestClassifier(**rf_params) #  'rf_params', sözlük içeriğini doğrudan parametreler olarak alır.

"""### **2.3. Model Eğitimi**

Modeli eğitmek için eğitim verilerini kullanırız. Modelin öğrenmesini sağlamak amacıyla fit() fonksiyonunu kullanıyoruz:
"""

start_time = time.time()

clf.fit(X_train, y_train)

end_time = time.time()
fit_time = end_time - start_time

print(f"Eğitim {round(fit_time, 6)} saniye sürdü.")

"""### **2.4. Modelin Performansını Değerlendirme**

Model eğitildikten sonra, doğruluk, F1 skoru ve diğer performans metriklerini değerlendirebiliriz. Bunun için, modelin test verisinde nasıl performans gösterdiğini görmek gerekir.
"""

y_pred = clf.predict(X_test)

"""1. Doğruluk (Accuracy)
Doğruluk, modelin doğru tahmin ettiği örneklerin tüm tahminlere oranıdır. Matematiksel olarak:

$$
\text{Doğruluk} = \frac{TP + TN}{TP + TN + FP + FN}
$$

- **TP**: Doğru Pozitif (True Positive)
- **TN**: Doğru Negatif (True Negative)
- **FP**: Yanlış Pozitif (False Positive)
- **FN**: Yanlış Negatif (False Negative)

<br>

2. Kesinlik (Precision)
Kesinlik, modelin pozitif olarak tahmin ettiği örneklerden gerçekten pozitif olanların oranını gösterir. Matematiksel formül:

$$
\text{Kesinlik} = \frac{TP}{TP + FP}
$$

<br>

3. Duyarlılık (Recall)
Duyarlılık, gerçekte pozitif olan örneklerin model tarafından doğru bir şekilde tahmin edilme oranıdır. Matematiksel formül:

$$
\text{Duyarlılık} = \frac{TP}{TP + FN}
$$

<br>

4. F1 Skoru (F1 Score)
F1 skoru, kesinlik ve duyarlılığın harmonik ortalamasıdır ve her iki metriği dengelemeye çalışır. Matematiksel formül:

$$
\text{F1 Skoru} = 2 \cdot \frac{\text{Kesinlik} \cdot \text{Duyarlılık}}{\text{Kesinlik} + \text{Duyarlılık}}
$$

"""

acc = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')  # 'macro', 'micro', 'weighted'
precision = precision_score(y_test, y_pred, average='macro')  # 'macro', 'micro', 'weighted'
recall = recall_score(y_test, y_pred, average='macro')  # 'macro', 'micro', 'weighted'

print(f"\n{clf.__class__.__name__} için Sınıflandırma Raporu:\n{report}")
print(f"\nDoğruluk: {round(acc, 6)}")
print(f"Kesinlik (Precision): {round(precision, 6)}")
print(f"Duyarlılık (Recall): {round(recall, 6)}")
print(f"F1 Skoru: {round(f1, 6)}")

"""Karışıklık matrisi (confusion matrix), modelin hangi sınıflar arasında hata yaptığı hakkında bilgi verir."""

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 8), dpi=100)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Tahmin Edilen Etiketler')
plt.ylabel('Gerçek Etiketler')
plt.title(f'Rastgele Orman (Random Forest) için Karışıklık Matrisi')
plt.show()

"""Bu metrikler, modelin ne kadar doğru ve etkili çalıştığını anlamamıza yardımcı olur.

Özellik önem dereceleri, hangi özelliklerin modelin tahminlerinde daha etkili olduğunu gösterir.
"""

if hasattr(clf, 'feature_importances_'):
    feature_importances = clf.feature_importances_
    feature_importance_df = pd.DataFrame({'Özellik': X_train.columns, 'Önem': feature_importances})
    feature_importance_df = feature_importance_df.sort_values(by='Önem', ascending=False)

    print(f"{clf.__class__.__name__} için Özelliklerin Önem Dereceleri:")
    print(feature_importance_df)

    feature_importance_df.to_csv(f"{clf.__class__.__name__}_ozellik_onemleri.csv", index=False)

    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance_df['Özellik'], feature_importance_df['Önem'], color='skyblue')
    plt.xlabel('Önem Derecesi')
    plt.ylabel('Özellikler')
    plt.title(f"{clf.__class__.__name__} Özellik Önem Dereceleri")
    plt.gca().invert_yaxis()
    plt.show()

"""### **2.5. Modeli Kaydetme ve Lokal Cihaza İndirme**

Modeli kaydetmek, eğitim sürecini tekrarlamadan modelin tahminler yapmasını sağlar, böylece **zaman ve kaynak tasarrufu** elde edilir. Kaydedilen model başka sistemlerde de kullanılabilir, bu da projelerin **esnekliğini artırır ve dağıtımı kolaylaştırır**. Ayrıca, modelin kaydedilmesi, **veri yeniden toplanmadan tahmin yapmayı mümkün kılar ve ekipler arası paylaşımı hızlandırır**, projelerin daha verimli ilerlemesini sağlar.
"""

joblib.dump(clf, f"{clf.__class__.__name__}_model.pkl")

from google.colab import files

files.download("/content/RandomForestClassifier_model.pkl")

"""## **3. Açıklanabilir Yapay Zeka için SHAP'ı Oluşturma**

SHAP (SHapley Additive exPlanations), bir modelin tahminlerini açıklamak için kullanılan bir yöntemdir. Oyun teorisine dayanan bu yöntem, her bir özelliğin model tahminine katkısını hesaplar. Özelliklerin etkisi, her özelliğin tüm olası alt kümelerdeki katkılarına göre adil bir şekilde belirlenir. Bu sayede her özellik, modelin tahminine yaptığı katkı kadar "ödüllendirilir". SHAP, bu katkıları görselleştirerek, özelliklerin model tahminlerine nasıl etki ettiğini anlamamıza yardımcı olur. Özellikle sağlık, finans ve ceza adaleti gibi alanlarda bu tür açıklanabilirlik, güven oluşturmak için oldukça önemlidir.

1. **SHAP kütüphanesini içe aktarın:** `import shap`
   - Bu, makine öğrenimi modellerinin çıktılarını açıklamak için kullanılan SHAP kütüphanesini içe aktarır.

2. **JS görselleştirmesini başlatın:** `shap.initjs()`
   - Bu, Jupyter defterinde SHAP grafiklerinin JavaScript görselleştirmesini başlatır.

Önceden eğitilmiş modeli, `joblib` kütüphanesi aracılığıyla tekrardan eğitmeye gerek kalmadan
 yüklenebilir.
"""

model = joblib.load('/content/RandomForestClassifier_model.pkl')
# y_pred = model.predict(X_test)
shap_values = np.load('/content/RF_shap_values.npy')

class_index_to_name = {
    0: 'Tarım Alanı',
    1: 'Yapay Alan',
    2: 'Çorak Arazi',
    3: 'Orman',
    4: 'Su Alanı'
}

def f(X):
    return model.predict_proba(X)

"""`y_train`'den özet grafiği için sınıf başına 50 örnek seçilir."""

classes = np.unique(y_train)
samples_per_class = 50

selected_indices = []
for c in classes:
    indices = np.where(y_train == c)[0]
    selected_indices.extend(np.random.choice(indices, samples_per_class, replace=False))

X_train_subset = X_train.iloc[selected_indices]
y_train_subset = y_train.iloc[selected_indices]

class_distribution = y_train_subset.map(class_index_to_name).value_counts()
print("y_train_subset içindeki sınıf dağılımı:")
print(class_distribution)

"""`y_test`'ten özet grafiği için sınıf başına 20 örnek seçilir."""

classes = np.unique(y_test)
samples_per_class = 20

selected_indices = []
for c in classes:

    indices = np.where(y_test == c)[0]
    selected_indices.extend(np.random.choice(indices, samples_per_class, replace=False))

X_test_subset = X_test.iloc[selected_indices]
y_test_subset = y_test.iloc[selected_indices]

class_distribution = y_test_subset.map(class_index_to_name).value_counts()
print("y_test_subset içindeki sınıf dağılımı:")
print(class_distribution)

"""Alt küme verilerini kullanarak özet grafiği oluşturulur."""

columns = X_test.columns

"""Bu fonksiyon, eğitilmiş bir modeli (`model`), giriş verisini (`X`), görselleştirme verisini (`X_display`) ve model adını (`model_name`) alır. SHAP açıklayıcı oluşturur, SHAP değerlerini hesaplar ve özelliklerin model tahminlerine etkisini gösteren bir özet grafik çizer.

Bu döngü, her model ve en iyi parametreleriyle modeli eğitir, ardından SHAP özet grafiğini çizmek için `visualize_shap` fonksiyonunu çağırır.
"""

shap.initjs()

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test_subset)

np.save('/content/RF_shap_values.npy', shap_values)

print(f"X_test_subset.shape: {X_test_subset.shape} - Bu, {X_test_subset.shape[0]} örnek ve {X_test_subset.shape[1]} özelliği içeren test verinizin alt kümesidir. Her satır bir örneği, her sütun ise bir özelliği temsil eder.")
print(f"shap_values[0].shape: {shap_values[0].shape} - Bu, ilk sınıf için SHAP değerleridir. {shap_values[0].shape[0]} özellik ve {shap_values[0].shape[1]} örnek içerir. Her satır bir özelliği, her sütun bir örneği temsil eder.")
print(f"shap_values.shape: {shap_values.shape} - Bu, genel SHAP değerlerinizin şeklidir. {shap_values.shape[0]} sınıf, {shap_values.shape[1]} özellik ve her sınıf başına {shap_values.shape[2]} örnek içerir. İlk boyut sınıfları, ikinci boyut özellikleri ve üçüncü boyut örnekleri temsil eder.")
print(f"X_test[:5].shape: {X_test[:5].shape} - Bu, test verinizin ilk 5 örneği olup {X_test[:5].shape[1]} özellik içerir. Her satır bir örneği, her sütun ise bir özelliği temsil eder.")
print(f"shap_values[:, :, 0].shape: {shap_values[:, :, 0].shape} - Bu, tüm sınıflar için ilk örnek için SHAP değerleridir. İlk boyut sınıfları, ikinci boyut özellikleri ve üçüncü boyut (bu durumda 0) örnek indeksini temsil eder.")

"""### **3.1. Bağımlılık Grafiği (Dependence Plot)**

Her özellik ve sınıf için ortalama mutlak SHAP değerleri, modelin tahminlerine her bir özelliğin katkısını ölçen bir analiz yöntemidir. SHAP değerleri, her bir özelliğin modelin çıktısındaki etkisini belirler. Ortalama mutlak SHAP değeri, her bir özelliğin tüm sınıflar için sağladığı katkıyı özetler ve bu sayede özelliklerin modeldeki göreceli önemini anlamamıza yardımcı olur. Bu analiz, modelin karar verme süreçlerini daha şeffaf hale getirir ve hangi özelliklerin sınıflandırmada daha fazla etkili olduğunu gösterir.
"""

# @markdown Grafiği çizdir.

shap_values_mean = np.mean(np.abs(shap_values), axis=0)
sorted_idx = np.argsort(np.mean(shap_values_mean, axis=1))

colors = plt.cm.viridis(np.linspace(0, 1, shap_values_mean.shape[1]))

plt.figure(figsize=(12, 7), dpi=200)
bottom = np.zeros(len(columns))

for class_idx in range(shap_values_mean.shape[1]):
    plt.barh(np.arange(len(columns)), shap_values_mean[sorted_idx, class_idx],
             left=bottom, height=0.6, color=colors[class_idx], alpha=0.7, label=class_index_to_name[class_idx])
    bottom += shap_values_mean[sorted_idx, class_idx]

plt.yticks(np.arange(len(columns)), np.array(columns)[sorted_idx], fontsize=10)
plt.xticks(fontsize=10)
plt.xlabel('Ortalama Mutlak SHAP Değeri', fontsize=12, fontweight='bold')
plt.ylabel('Özellik', fontsize=12, fontweight='bold')
plt.title("Her Özellik ve Sınıf İçin Ortalama Mutlak SHAP Değerleri (Rastgele Orman Sınıflandırıcı)", fontsize=13, fontweight='bold')
plt.legend(fontsize=11, loc='center left', bbox_to_anchor=(1, 0.5), fancybox=True, shadow=True)
plt.grid(axis='x', linestyle='--', alpha=0.3)
plt.tight_layout()

plt.savefig('/content/Ortalama Mutlak SHAP Değerleri.png', bbox_inches='tight')
plt.show()

"""Bağımlılık grafiği, özellikle etkileşimleri gözlemlememize yardımcı olur; bir özelliğin etkisi, diğer özelliklerle nasıl değişiyorsa, bu etkileşimlerin nasıl şekillendiğini gösterir. Bu analiz, modelin daha doğru yorumlanmasına olanak tanır ve özellikler arasındaki ilişkilerin modelin tahminlerine nasıl yansıdığını açıkça ortaya koyar. Tabloda, sırasıyla her sınıf için en çok etkilenen 3 değişkeni alınır."""

# @markdown Grafiği çizdir.

shap_values_mean = np.mean(np.abs(shap_values), axis=0)

fig, axs = plt.subplots(5, 3, figsize=(10, 15), dpi=100)

axs_flat = axs.flatten()

for class_index in range(shap_values_mean.shape[1]):

    sorted_features = np.argsort(shap_values_mean[:, class_index])[::-1]
    top_features = sorted_features[:3]  # İlk 3 özellik

    for i, feature_index in enumerate(top_features):
        title = f"{columns[feature_index]} Özellik için SHAP Analizi ({class_index_to_name[class_index]})"
        shap.dependence_plot(feature_index, shap_values[:, :, class_index], X_test_subset, ax=axs_flat[class_index*3 + i], show=False, interaction_index=None, color="#0070c0")
        axs_flat[class_index*3 + i].axhline(y=0.00, color='gray', linestyle='--', linewidth=0.5)  # y=0.00 için gri '--' çizgisi ekle
        axs_flat[class_index*3 + i].set_title(title, fontsize=10, fontweight='bold', pad=8)
        axs_flat[class_index*3 + i].set_xlabel(f"{columns[feature_index]}", fontsize=8, fontweight='bold', labelpad=5)
        axs_flat[class_index*3 + i].set_ylabel(f"SHAP Değeri ({columns[feature_index]})", fontsize=8, fontweight='bold', labelpad=8)
        axs_flat[class_index*3 + i].tick_params(axis='both', which='major', labelsize=6)
        axs_flat[class_index*3 + i].grid(axis='x', linestyle='--', alpha=0.3)

plt.tight_layout()
plt.savefig('dependence_plots_grid.png', bbox_inches='tight', dpi=200)
plt.show()

"""### **3.2. Özet Grafiği (Summary Plot)**"""

# @markdown Grafiği çizdir.

for i in range(5):
    plt.figure(figsize=(8, 6), dpi=100)
    shap.summary_plot(shap_values[:, :, i], features=X_test_subset, plot_type="dot", feature_names=columns, max_display=100, show=False)
    plt.title(f"{class_index_to_name[i]}  (Rastgele Orman (Random Forest) Sınıflandırıcı)", fontsize=14, fontweight='bold')
    plt.xlabel("SHAP Değeri", fontsize=12, fontweight='bold')
    plt.ylabel("Özellik", fontsize=12, fontweight='bold')
    plt.savefig(f'shap_values_plot_{class_index_to_name[i]}.png', bbox_inches='tight')
    plt.show()

"""### **3.3. Etkileşim Grafiği (Force Plot)**"""

shap.initjs()

idx = 0
class_index = 0

shap_values_idx = shap_values[idx, :, class_index]
shap.force_plot(explainer.expected_value[class_index], shap_values_idx, X_test_subset.iloc[idx, :])

class_name = class_index_to_name[class_index]
print(f"İndeks {idx}: {class_name}")

"""### **3.4. SHAP Sahne Görselleştirmesi**"""

shap_agri = np.load('/content/agriculture_RF_shap_values.npy')
shap_arti = np.load('/content/artificial_RF_shap_values.npy')
shap_barr = np.load('/content/barren_RF_shap_values.npy')
shap_fore = np.load('/content/forest_RF_shap_values.npy')
shap_wate = np.load('/content/water_RF_shap_values.npy')

reshaped_values = shap_agri.reshape(2500, -1)[:, :5]  # 'shap_agri' değişkeni değiştirilerek diğer sınıfların görselleştirmesi yapılabilir.
reshaped_values = reshaped_values.reshape(50, 50, 5)

reshaped_values = reshaped_values[:32, :32, :]

global_min = np.min(reshaped_values)
global_max = np.max(reshaped_values)

fig, axs = plt.subplots(1, 5, figsize=(30, 7), dpi=200)

for i in range(5):
    im = axs[i].imshow(reshaped_values[:, :, i], cmap='vlag', vmin=global_min, vmax=global_max)
    axs[i].set_title(class_index_to_name[i], fontsize=13)
    axs[i].axis('off')

cbar_ax = fig.add_axes([0.16, 0.1, 0.7, 0.05])
cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')
cbar.set_label('SHAP Value', labelpad=15)

plt.suptitle('Farklı Arazi Sınıfları İçin SHAP Değerlerinin Görselleştirilmesi', fontsize=20, fontweight='bold')
plt.subplots_adjust(bottom=0.2, top=0.90)
plt.savefig('/content/SHAP_visual.png')
plt.show()

"""## **4. Verileri Lokal Cihaza İndirme**"""

from google.colab import files

files.download("/content/Ortalama Mutlak SHAP Değerleri.png")
files.download("/content/shap_values_plot_Orman.png")
files.download("/content/shap_values_plot_Su Alanı.png")
files.download("/content/shap_values_plot_Tarım Alanı.png")
files.download("/content/shap_values_plot_Yapay Alan.png")
files.download("/content/shap_values_plot_Çorak Arazi.png")
files.download("/content/dependence_plots_grid.png")
files.download("/content/SHAP_visual.png")

files.download("/content/RF_shap_values.npy")

"""**Akılınıza takılan bir soru varsa, lütfen bizimle paylaşın. Yardımcı olmaktan memnuniyet duyarız:**

<br>

- **Doğu İlmak** - doguilmak@gmail.com

- **Doç. Dr. Muzaffer Can IBAN** - caniban@mersin.edu.tr
"""